<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS 184 Path Tracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 3-1: Path Tracer</h1>
<h2 align="middle">Chi-Feng Wang, (CS184-ACB), Maggie Yi (CS184-ACF)</h2>

<!-- Add Website URL -->
<h2 align="middle">Website URL: <a href="TODO">TODO</a></h2>

<br><br>


<div align="center">
  <table style="width=100%">
      <tr>
          <td align="middle">
          <img src="images/example_image.png" width="480px" />
          <figcaption align="middle">Results Caption: my bunny is the bounciest bunny</figcaption>
      </tr>
  </table>
</div>

<h2 align="middle">Overview</h2>
<p>
    For this project, we created a ray tracing rendering engine that can render DAE files.
</p>
<br>

<h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

<h3>
  Walk through the ray generation and primitive intersection parts of the rendering pipeline.
</h3>
<p>
    To generate a ray passing through the camera at point (x, y), we translate the image coordinates
    to camera space, generate the ray in camera space, and transofrm it back into a ray in the world space.
    We first calculate the (x, y) coordinates in the camera space, which we can do since we know the bottom
    left and top right corner coordinates of the image in the camera space. The ray generated will have two
    components: an origin and a direction. The origin is "pos", the camera position in world space, and the
    direction is the the camera-to-world roation matrix multiplied by the (x, y) coordinates in the camera space.
    <br />
    Once a ray is generated, we update the color of each pixel in PathTracer::raytrace_pixel(), which generates
    ns_aa random rays in the pixel and computes the average of all color values of the ray in the pixel.
    <br />
    We implemented two ray-primitive intersections in this task: ray-triangle intersection and ray-sphere 
    intersection. For ray-sphere intersection, we used the equation from lecture, which calculates the
    t-value of the intersection between the ray and sphere. There is an intersection if t lies within min_t and max_t
    of the input ray. Every time there is an intersection, we update the max_t of the ray. The triangle intersection
    algorithm we used will be explained below.
</p>
<br>

<h3>
  Explain the triangle intersection algorithm you implemented in your own words.
</h3>
<p>
    Originally, we used a more intuitive triangle intersection algorithm. We computed the normal of the triangle, and checked
    whether the ray is parallel to the plane by taking the dot product of the ray's direction and the normal. If the ray is parallel
    to the plane of the triangle, they cannot intersect. Then, we compute t, the value of the "length" of the ray when it
    intersects the plane. If this value is outside of [ray.min_t, ray.max_t], then there is no intersection. If this value
    is less than 0, there is no intersection. We then calculate the intersection point p in the triangle, and use
    a similar method as Project 1 to test whether or not point p is inside the triangle. If yes, then we have an intersection.
    <br />
    However, we saw on Ed that other people were using a faster algorithm, known as the Moller-Trumbore intersection algorithm.
    This algorithm is a fast method of calculating the intersection without needing to compute the plane equation, and provides
    us with barycentric coordinates that we can use for interpolating the surface normal at the intersection point. Similar to
    before, we first check if the ray is parallel to the triangle by calculating the dot product between the ray's direction and the
    triangle plane normal. Then, the Moller-Trumbore intersection algorithm sets up a system of linear equations O-v1 = -tD + u(v2-v1) + v(v3-v1)
    where v1, v2, and v3 are the vertices of the triangle, D is the ray's direction vector, O is tha ray's origin, and t, u, v are the variables we
    solve for. If there is a solution where u and v are both positive and sum up to less than 1, and where t is within [ray.min_t, ray.max_t],
    then there is a valid intersection.
</p>
<br>

<h3>
  Show images with normal shading for a few small .dae files.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part1empty.png" align="middle" width="400px"/>
        <figcaption>sky/CBempty.dae</figcaption>
      </td>
      <td>
        <img src="images/part1cube.png" align="middle" width="400px"/>
        <figcaption>simple/cube.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part1spheres.png" align="middle" width="400px"/>
        <figcaption>sky/CBspheres.dae</figcaption>
      </td>
      <td>
        <img src="images/part1cow.png" align="middle" width="400px"/>
        <figcaption>meshedit/cow.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


<h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
<!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

<h3>
  Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
</h3>
<p>
    First, we compute a bounding box of the list of primitives and create a new BVHNode with that bounding box.
    We figure out whether or not that BVHNode is a leaf node by checking if there is no more than max_leaf_size primitives
    in the bounding box. If it is a leaf node, we set the node's start and end iterators to the iterators of the list
    of primitives.
    <br />
    If it isn't a leaf node, we divide the primitives into a "left" and a "right" group. First, we pick the longest axis (either x, y, or z),
    since we want to split along the widest axis. Then, we sort the list of primitives by their position along that axis.
    Then, we compute the average of all centroids of all the primitives. The split point we use will be point
    in which the average lies along the longest axis. We find the first primitive that lies beyond the split point, and
    set a pointer named bound pointing to that primitive
    We then recursively call BVHAccel:construct_bvh() on the left side of the split point (e.g. from "start" to "bound")
    and the right side of the split point (e.g. from "bound" to "end"). We initialize bound to be start, so even if all primitives lie
    on one side of the split point, there will be no segfault.
</p>

<h3>
  Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part2cbbunny.png" align="middle" width="400px"/>
        <figcaption>CBBunny.dae</figcaption>
      </td>
      <td>
        <img src="images/part2cblucy.png" align="middle" width="400px"/>
        <figcaption>CBlucy.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part2blob.png" align="middle" width="400px"/>
        <figcaption>blob.dae</figcaption>
      </td>
      <td>
        <img src="images/part2dragon.png" align="middle" width="400px"/>
        <figcaption>dragon.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
</h3>
<p>
    For the cow, rendering time with BVH acceleration takes 0.0789s, averaging 2.672023 intersection tests per ray, and 5.2658 million rays per second.
    Rendering time without BHV acceleration takes 43.2549, averaging 1367.322556 intersection tests per ray, and 0.0111 million rays per second.
    For the bunny, rendering time with BVH acceleration is 0.0845s, averaging 2.405373 intersection tests per ray, and 4.9741 million rays per second.
    Rendering time without BHV acceleration takes 209.2882s, averaging 6383.757855 intersection tests per ray, and 0.0023 million million rays per second.
    From this, we can see that BVH acceleration speeds up rendering times by orders of magnitude by reducing the number of intersection tests we 
    have to compute per ray. That way, we can render more rays per second, speeding up the rendering time.
</p>
<br>

<h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
<!-- Walk through both implementations of the direct lighting function.
Show some images rendered with both implementations of the direct lighting function.
Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

<h3>
  Walk through both implementations of the direct lighting function.
</h3>
<p>
    YOUR RESPONSE GOES HERE
</p>

<h3>
  Show some images rendered with both implementations of the direct lighting function.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <!-- Header -->
    <tr align="center">
      <th>
        <b>Uniform Hemisphere Sampling</b>
      </th>
      <th>
        <b>Light Sampling</b>
      </th>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example1.dae</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example1.dae</figcaption>
      </td>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example2.dae</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example2.dae</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>
<br>

<h3>
  Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="200px"/>
        <figcaption>1 Light Ray (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="200px"/>
        <figcaption>4 Light Rays (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="200px"/>
        <figcaption>16 Light Rays (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="200px"/>
        <figcaption>64 Light Rays (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
    YOUR EXPLANATION GOES HERE
</p>
<br>

<h3>
  Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
</h3>
<p>
    YOUR RESPONSE GOES HERE
</p>
<br>


<h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
<!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

<h3>
  Walk through your implementation of the indirect lighting function.
</h3>
<p>
    YOUR RESPONSE GOES HERE
</p>
<br>

<h3>
  Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example1.dae</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example2.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>Only direct illumination (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>Only indirect illumination (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    YOUR EXPLANATION GOES HERE
</p>
<br>

<h3>
  For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    YOUR EXPLANATION GOES HERE
</p>
<br>

<h3>
  Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>1 sample per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>2 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>4 samples per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>8 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>16 samples per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>64 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>1024 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    YOUR EXPLANATION GOES HERE
</p>
<br>


<h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
<!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

<h3>
  Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
</h3>
<p>
    To decrease noise, we increase the number of samples per pixel. However, some pixels may converge faster,
    while other pixels converge slower. Adaptive sampling is a sampling method that terminates
    generating more samples when the pixel has converged. This allows us to concentrate
    the samples in parts of the image that converge slower (are more difficult).
    <br />
    My implementation of adaptive sampling calculates I, the pixel's convergence, every samplesPerBatch samples. 
    At each sample, we keep track of the sum of all illuminances of all past samples (s1), as well as the sum of all illuminances squared of all past samples (s2).
    Every samplesPerBatch, we calculate the mean and variance of all samples so far (n samples), with mean = s1/n and variance = (1/n-1)*(s2 - (s1**2 / n))
    Then we calculate convergence as 1.96*sqrt(variance)/sqrt(n). If the value of convergence is less than maxTolerance*mean, then the pixel
    has converged and we stop tracing more rays for that pixel. 
</p>
<br>

<h3>
  Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>Rendered image (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>Rendered image (example2.dae)</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (example2.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


</body>
</html>
